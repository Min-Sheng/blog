---
title: 成功大學「深度學習在電腦視覺上之應用」課程收穫分享
date: 2018-4-5 12:15:00
excerpt: 師父領進門，修行看個人
header:
  image: /assets/images/cifar-10_accuracy.png
  teaser: /assets/images/tensorboard_graph_in_my_cifar-10_cnn_model.png
keywords: 
  - 'essay'
  - 'teaching'
  - 'IT'
category: essay
tags: [essay]
---

「師父領進門，修行看個人」用來形容這門課大概是最為貼切的吧，

當初只憑著想要好好了解深度學習、建立紮實的理論與實務知識，以利將來進研究所能在此根基上有一番作為，因而選修葉老師開設的「深度學習在電腦視覺上之應用」。

如今回頭檢視自己的成長軌跡，才驚覺在老師與助教的教導與帶領之下，不僅僅是達成當時小小的目標，

更因為自己在作業上的一些「想要突破困境變得更好」的堅持，額外獲得想像不到的大收穫！

在第一周我學習到深度學習的基石： Perceptron 、 Logistic Regression 、 Fully Connected Neural Network 、 Gradient Descent 、 Forward and Backward Propagation ，

從最根本的數學脈絡開始理解，才能踏實地掌握深度學習的精髓。

而在第一次作業中，我也自行推導一次 Backward Propagation 的公式，並嘗試使用  Learning Rate Step Decay 的方法改善模型的 loss ，

這讓深度學習對我而言不再只是門外漢說的黑盒子。

第二周習得 Convolution Neutral Network  的原理與方法，如： Padding 、 Stride 、 Convolution 、 Pooling ，

並且在第二次作業中，使用 Low-level Tensorflow APIs 實作出第一個 CNN 來分類 CIFAR 10 的影像，

在通盤了解 CNN 最初的設計理念、演算法之後，也就能更有系統性地改善模型、調整超參數 ( Hyperparameter ) ，

而由較底層的 Tensorflow 開始著手，方能了解這些理論是如何實踐為程式碼的轉換過程。

為了優化 CNN 的一些缺陷，我花費了很多心思，

例如：前後嘗試 He Initialization ( Xavier Initialization的改良版 )、 Batch Normalization 、 Selu ( Self-Normalizing ReLU, SNN ) 來改善  Gradient Vanishing/Exploding Problem 、 Differential Dropout 、 Random Shuffling 、 L2 Regularization 避免 overfitting 等等，

看到準確率因為自己努力不懈而有所提昇是我進步的原動力，藉由不斷累積這些功夫，更使得我的知識與能力能夠快速增進！

我覺得這種「想要突破困境變得更好」的心態是一種良性循環，

就像我已經達到將近 80% 的準確率後，就會有我一定能在第三次作業中衝到 90% 的想法，

所以我又更進一步去參考許多文獻，

研究改善 CNN 架構的 NIN (Network in Network)，知道原來所謂的 Mlpconv (multilayer perceptron convolution) 是在 conv layers 中間加上多層的 fully connected layers (實作上使用 1x1 conv) 以提高conv layer 的非線性感知能力、以及透過 Global Average Pooling 取代 fully connected layers 可以不失成效地大幅減少 parameters ，

最後加上 Learning Rate Step Decay 與 Data Augmentation 果真成功使準確率達到 90% ，也讓我獲得上台與同學分享的機會。

第三、四周的課程提及視覺化工具 TensorBoard 的使用、 CNN 的衍生架構： LeNet 、 AlexNet 、 VGG 、 GoogLeNet 、 ResNet 、 DenseNet 、以及能快速建構 prototype 的 Keras 。

我認為這門課就像是為我們勾勒出一張風景畫的草稿輪廓，而色彩細節就留給我們盡情地描繪，

雖然有些內容無法詳細地深入探討，但是老師都很用心地製作講義與附上文獻連結，有了先前精實的訓練，往後自己想深入研究都不成問題。

即將前往台大資訊網路與多媒體研究所的我，因為是從生物醫學工程的領域半路出家，內心總是感到徬徨與不安，

這門課就像一顆定心丸，讓我對於將來深度學習的研究框架比較熟悉。

雖然目前尚未清楚自己未來的學術發展，打算進入實驗室之後再好好做決定，

但我認為一個好的深度學習的成就，就在於能否應用在創新、實用的議題上去解決別人無法妥善解決的問題，

正如我的指導教授徐宏民教授所說，一個研究是否成功，

只在於這研究是否能讓人大聲讚嘆：Wow, it’s great!

*****

如果對於我如何使用 CNN 分類 CIFAR 10 的影像，並達到 90% 準確率，

可以參考我的 github : [Min-Sheng/deep-learning-cv](https://github.com/Min-Sheng/deep-learning-cv)

在此也提供我與同學們分享的[簡報](https://min-sheng.github.io/deep-learning-cv/week3/Project/%E6%B7%B1%E5%BA%A6%E5%AD%B8%E7%BF%92%E5%A0%B1%E5%91%8A_%E9%86%AB%E5%B7%A5%E7%B3%BB_%E5%90%B3%E6%97%BB%E6%98%87.html)：

<iframe src="https://min-sheng.github.io/deep-learning-cv/week3/Project/%E6%B7%B1%E5%BA%A6%E5%AD%B8%E7%BF%92%E5%A0%B1%E5%91%8A_%E9%86%AB%E5%B7%A5%E7%B3%BB_%E5%90%B3%E6%97%BB%E6%98%87.html" style="width:100%; height:650px;" frameborder="0"></iframe> 

以及[最後一份作業的 source code](https://min-sheng.github.io/deep-learning-cv/week3/Project/final_dlnd_image_classification_with_DA.html) ：

<iframe src="https://min-sheng.github.io/deep-learning-cv/week3/Project/final_dlnd_image_classification_with_DA.html" style="width:100%; height:800px;" frameborder="0" scrolling="yes"></iframe>
